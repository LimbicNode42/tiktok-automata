{
  "url": "https://www.tomshardware.com/tech-industry/artificial-intelligence/ai-disruptor-deepseeks-next-gen-model-delayed-by-nvidia-h20-restrictions-short-supply-of-accelerators-hinders-development?utm_source=tldrnewsletter",
  "title": "AI disruptor DeepSeek's next-gen model delayed by Nvidia GPU export restrictions to China",
  "original_content": "Skip to main content Recommended reading (Image credit: Nvidia) DeepSeek attracted a lot of attention with its R1 AI model earlier this year, but it looks like development of the next-generation R2 model has stalled due to shortage of Nvidia's H20 processors in China, reports The Information . DeepSeek itself has not commented on when its R2 model is set to be available. DeepSeek used a cluster consisting of 50,000 Hopper GPUs \u2014 including 30,000 H20s, 10,000 H800s, and 10,000 H100s \u2014 obtained by its investor High-Flyer Capital Management \u2014 to train its R1 model. It is unclear whether R2 has already been fully pre-trained. The Information reports citing two individuals familiar with the project that DeepSeek team has been working intensively on the model, but CEO Liang Wenfeng is not yet satisfied with its capabilities. Work continues internally to improve performance before the model is cleared for deployment. R1 was quickly and widely adopted by a range of users, including private startups, big companies, and government-affiliated groups. Most of these users ran the model on Nvidia's H20 processors. Now that H20 shipments are restricted, it is already causing problems, limiting how R1 is used today and making it harder to get ready for the launch of R2, according to The Information report. Should DeepSeek's upcoming R2 model surpass the capabilities of currently available open alternatives, usage is expected to surge beyond what Chinese cloud platforms can handle, according to staff at those firms cited by The Information . Most organizations relying on the earlier R1 model are said to operate it using Nvidia's H20 processors, which are now in short supply. The U.S. government restricted sales of Nvidia's H20 processors for AI training and inference in mid-April. While the unit is a severely cut-down version of the popular H100 GPU, due to reliance of Chinese AI companies on Nvidia's CUDA software stack, H20 was a quite popular product among such entities in the People's Republic with Nvidia selling billions of dollars' worth of H20 processors every quarter. DeepSeek's AI software is reportedly optimized for Nvidia's hardware, which makes the company particularly vulnerable to U.S. policy decisions. Although the company claims to have developed its models using far fewer resources than U.S. companies like OpenAI, the recent export curbs highlight a critical weakness: China's top AI companies remain heavily dependent on American hardware. Meanwhile, OpenAI has unofficially accused DeepSeek of using its proprietary models during the development of R1, although the company has not addressed these claims publicly. Follow Tom's Hardware on Google News to get our up-to-date news, analysis, and reviews in your feeds. Make sure to click the Follow button. Stay On the Cutting Edge: Get the Tom's Hardware",
  "tiktok_summary": "The tech industry just witnessed something unprecedented: Nvidia's next-gen GPU shortage is crippling the development of DeepSeek's revolutionary AI model R2. Yeah, you heard that right - a shortage of Nvidia GPUs in China is putting the brakes on one of the most promising AI advancements in years. Imagine having 50,000 GPUs under your belt - that's like having an entire army of computing power at your disposal. But what happens when those GPUs are in short supply? Well, let me tell you, it's chaos. Or at least, it's about to get chaotic. DeepSeek's R1 model took the world by storm, being adopted by everyone from private labs to major corporations. But now, the company's next-gen model, R2, is stuck in neutral. And why? Because Nvidia's H20 processors, the crown jewels of their lineup, are nowhere to be found in China. That's right, folks, we're talking about the same Nvidia GPUs that made R1 so powerful in the first place. But wait, there's more and it's unhinged: did you know that DeepSeek's R1 model required a whopping 50,000 GPUs to train? I mean, that's a whole lot of processing power. And now, they can't even get enough of those GPUs to make R2 happen. It's like trying to build a skyscraper without the foundation - it just won't work. Now, here's another mind-blowing fact: Nvidia's H20 processors are basically the holy grail of GPUs. They offer unmatched performance and efficiency, making them the go-to choice for many top-tier AI projects. So, when you combine that with the fact that DeepSeek's R2 model is still stuck in limbo... well, let's just say things are getting interesting.",
  "summary_length": 1615,
  "summary_words": 275,
  "summarized_at": "2025-06-28T00:42:46.551560"
}